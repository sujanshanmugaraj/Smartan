# multi_person_exercise_analyzer.py
import cv2
import numpy as np
import os
import csv
import json
import pandas as pd
from datetime import datetime
from collections import defaultdict
import base64
from io import BytesIO

import matplotlib
matplotlib.use('Agg')  
import matplotlib.pyplot as plt


class OpenPoseDetector:
    def __init__(self, model_folder="models/"):
        """Initialize OpenPose detector"""
        self.model_folder = model_folder
        self.net = None
        self.output_layers = None
        self.setup_openpose()
    
    def setup_openpose(self):
        """Setup OpenPose using OpenCV DNN"""
        try:
            
            prototxt_path = os.path.join(self.model_folder, "pose_deploy_linevec.prototxt")
            weights_path = os.path.join(self.model_folder, "pose_iter_440000.caffemodel")
            
            if not os.path.exists(prototxt_path) or not os.path.exists(weights_path):
                print("[‚ö†Ô∏è WARNING] OpenPose model files not found!")
                print("Please download:")
                print("1. pose_deploy_linevec.prototxt")
                print("2. pose_iter_440000.caffemodel")
                print("From: https://github.com/CMU-Perceptual-Computing-Lab/openpose/tree/master/models/pose/coco")
                
                os.makedirs(self.model_folder, exist_ok=True)
                self.create_dummy_model_files(prototxt_path, weights_path)
            
            self.net = cv2.dnn.readNetFromCaffe(prototxt_path, weights_path)
            print("[‚úÖ SUCCESS] OpenPose model loaded successfully")
            
        except Exception as e:
            print(f"[‚ùå ERROR] Failed to load OpenPose: {e}")
            print("Using fallback method...")
            self.net = None
    
    def create_dummy_model_files(self, prototxt_path, weights_path):
        """Create dummy files for testing purposes"""
        print("[üîß SETUP] Creating dummy model files for testing...")
        
        prototxt_content = '''name: "OpenPose"
input: "image"
input_dim: 1
input_dim: 3
input_dim: 368
input_dim: 368

layer {
  name: "dummy"
  type: "Input"
  top: "dummy"
}'''
        
        with open(prototxt_path, 'w') as f:
            f.write(prototxt_content)
        
        with open(weights_path, 'wb') as f:
            f.write(b'')
        
        print("[‚ö†Ô∏è NOTE] Using dummy files - pose detection will be simulated")
    
    def detect_poses(self, frame):
        """Detect poses in frame and return multiple person keypoints"""
        if self.net is None:
            return self.simulate_multi_person_detection(frame)
        
        try:
            height, width = frame.shape[:2]
            
            blob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (368, 368), (0, 0, 0), swapRB=False, crop=False)
            self.net.setInput(blob)
            
            output = self.net.forward()
            
            return self.parse_openpose_output(output, width, height)
            
        except Exception as e:
            print(f"[‚ö†Ô∏è WARNING] OpenPose detection failed: {e}")
            return self.simulate_multi_person_detection(frame)
    
    def simulate_multi_person_detection(self, frame):
        """Simulate detection of multiple people for testing"""
        height, width = frame.shape[:2]
        
        people = []
        
        # Person 1 (left side)
        person1_keypoints = {}
        person1_keypoints[0] = [width * 0.25, height * 0.15]  # nose
        person1_keypoints[1] = [width * 0.23, height * 0.18]  # neck
        person1_keypoints[2] = [width * 0.20, height * 0.25]  # right shoulder
        person1_keypoints[3] = [width * 0.18, height * 0.35]  # right elbow
        person1_keypoints[4] = [width * 0.16, height * 0.45]  # right wrist
        person1_keypoints[5] = [width * 0.26, height * 0.25]  # left shoulder
        person1_keypoints[6] = [width * 0.28, height * 0.35]  # left elbow
        person1_keypoints[7] = [width * 0.30, height * 0.45]  # left wrist
        person1_keypoints[8] = [width * 0.22, height * 0.50]  # mid hip
        person1_keypoints[9] = [width * 0.20, height * 0.50]  # right hip
        person1_keypoints[10] = [width * 0.18, height * 0.65]  # right knee
        person1_keypoints[11] = [width * 0.16, height * 0.80]  # right ankle
        person1_keypoints[12] = [width * 0.24, height * 0.50]  # left hip
        person1_keypoints[13] = [width * 0.26, height * 0.65]  # left knee
        person1_keypoints[14] = [width * 0.28, height * 0.80]  # left ankle
        
        people.append({"keypoints": person1_keypoints, "confidence": 0.8})
        
        # Person 2 (right side)
        person2_keypoints = {}
        person2_keypoints[0] = [width * 0.75, height * 0.15]  # nose
        person2_keypoints[1] = [width * 0.73, height * 0.18]  # neck
        person2_keypoints[2] = [width * 0.70, height * 0.25]  # right shoulder
        person2_keypoints[3] = [width * 0.68, height * 0.35]  # right elbow
        person2_keypoints[4] = [width * 0.66, height * 0.45]  # right wrist
        person2_keypoints[5] = [width * 0.76, height * 0.25]  # left shoulder
        person2_keypoints[6] = [width * 0.78, height * 0.35]  # left elbow
        person2_keypoints[7] = [width * 0.80, height * 0.45]  # left wrist
        person2_keypoints[8] = [width * 0.72, height * 0.50]  # mid hip
        person2_keypoints[9] = [width * 0.70, height * 0.50]  # right hip
        person2_keypoints[10] = [width * 0.68, height * 0.65]  # right knee
        person2_keypoints[11] = [width * 0.66, height * 0.80]  # right ankle
        person2_keypoints[12] = [width * 0.74, height * 0.50]  # left hip
        person2_keypoints[13] = [width * 0.76, height * 0.65]  # left knee
        person2_keypoints[14] = [width * 0.78, height * 0.80]  # left ankle
        
        people.append({"keypoints": person2_keypoints, "confidence": 0.7})
        
        return people
    
    def parse_openpose_output(self, output, width, height):
        """Parse OpenPose output to extract multiple person keypoints"""
        people = []
        
        num_keypoints = 18
        
        heatmaps = output[0, :num_keypoints, :, :]
        
        for person_id in range(2):  
            keypoints = {}
            confidence = 0.5 + person_id * 0.1
            
            for i in range(num_keypoints):
                heatmap = heatmaps[i]
                _, max_val, _, max_loc = cv2.minMaxLoc(heatmap)
                
                if max_val > 0.1: 
                    x = int(max_loc[0] * width / heatmap.shape[1])
                    y = int(max_loc[1] * height / heatmap.shape[0])
                    keypoints[i] = [x, y]

            if len(keypoints) > 5:  
                people.append({"keypoints": keypoints, "confidence": confidence})
        
        return people

def calculate_angle(a, b, c):
    """Calculate angle between three points"""
    a = np.array(a)
    b = np.array(b)  
    c = np.array(c)
    
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    
    if angle > 180.0:
        angle = 360-angle
        
    return angle

def smooth_signal(signal, window_size):
    """Simple smoothing function"""
    if len(signal) < window_size:
        return signal
    smoothed = []
    for i in range(len(signal)):
        start = max(0, i - window_size//2)
        end = min(len(signal), i + window_size//2 + 1)
        smoothed.append(np.mean(signal[start:end]))
    return smoothed

def check_bicep_curl(keypoints):
    """Check bicep curl form using OpenPose keypoints"""
    try:
        
        # Check right arm
        if 2 in keypoints and 3 in keypoints and 4 in keypoints:
            shoulder = keypoints[2]
            elbow = keypoints[3]
            wrist = keypoints[4]
            angle = calculate_angle(shoulder, elbow, wrist)
            
            if angle > 160:
                return angle, "Correct", elbow
            elif angle < 30:
                return angle, "Too Curled", elbow
            else:
                return angle, "Correct", elbow
        
        # Check left arm if right arm not available
        elif 5 in keypoints and 6 in keypoints and 7 in keypoints:
            shoulder = keypoints[5]
            elbow = keypoints[6]
            wrist = keypoints[7]
            angle = calculate_angle(shoulder, elbow, wrist)
            
            if angle > 160:
                return angle, "Correct", elbow
            elif angle < 30:
                return angle, "Too Curled", elbow
            else:
                return angle, "Correct", elbow
        
        return 0, "No Detection", [0, 0]
        
    except Exception as e:
        return 0, "Error", [0, 0]

def check_lateral_raise(keypoints):
    """Check lateral raise using OpenPose keypoints"""
    try:
        # Check left arm: shoulder (5) and wrist (7)
        if 5 in keypoints and 7 in keypoints:
            shoulder_y = keypoints[5][1]
            wrist_y = keypoints[7][1]
            y_diff = abs(shoulder_y - wrist_y)
            joint = keypoints[7]
            
            if 50 <= y_diff <= 120:
                return y_diff, "Good", joint
            elif y_diff < 50:
                return y_diff, "Too Low", joint
            else:
                return y_diff, "Good", joint
        
        return 0, "No Detection", [0, 0]
        
    except Exception as e:
        return 0, "Error", [0, 0]

def check_squat(keypoints):
    """Check squat form using OpenPose keypoints"""
    try:
        # Check right leg: hip (9), knee (10), ankle (11)
        if 9 in keypoints and 10 in keypoints and 11 in keypoints:
            hip = keypoints[9]
            knee = keypoints[10]
            ankle = keypoints[11]
            angle = calculate_angle(hip, knee, ankle)
            
            if 90 <= angle <= 150:
                return angle, "Correct", knee
            elif angle > 160:
                return angle, "Too High", knee
            else:
                return angle, "Good", knee
        
        return 0, "No Detection", [0, 0]
        
    except Exception as e:
        return 0, "Error", [0, 0]

def check_jumping_jack(keypoints):
    """Check jumping jack using OpenPose keypoints"""
    try:
        # Check arms: left wrist (7), right wrist (4)
        # Check legs: left ankle (14), right ankle (11)
        
        if 4 in keypoints and 7 in keypoints and 11 in keypoints and 14 in keypoints:
            left_wrist = keypoints[7]
            right_wrist = keypoints[4]
            left_ankle = keypoints[14]
            right_ankle = keypoints[11]
            
            hand_dist = abs(left_wrist[0] - right_wrist[0])
            foot_dist = abs(left_ankle[0] - right_ankle[0])
            
            if hand_dist > 100 and foot_dist > 50:
                return (hand_dist, foot_dist), "Good", left_wrist
            else:
                return (hand_dist, foot_dist), "Closed", left_wrist
        
        return (0, 0), "No Detection", [0, 0]
    
    except Exception as e:
        return (0, 0), "Error", [0, 0]

class MultiPersonExerciseAnalyzer:
    def __init__(self, exercise_type, input_path, output_dir='output_videos'):
        self.exercise_type = exercise_type
        self.input_path = input_path
        self.output_dir = output_dir
        self.output_path = os.path.join(output_dir, f'{exercise_type}_multi_person_output.mp4')
        self.log_path = os.path.join(output_dir, f'{exercise_type}_multi_person_log.csv')
        self.summary_path = os.path.join(output_dir, f'{exercise_type}_multi_person_summary.json')
        self.graphs_dir = os.path.join(output_dir, 'graphs')
        
        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(self.graphs_dir, exist_ok=True)
        
        self.pose_detector = OpenPoseDetector()
        
        self.people_data = defaultdict(lambda: {
            'rep_count': 0,
            'stage': "down",
            'metric_buffer': [],
            'color': np.random.randint(0, 255, 3).tolist()
        })
        
        self.SMOOTH_WINDOW = 5
    
    def process_video(self):
        """Main video processing function for multiple people"""
        print(f"[üöÄ START] Processing {self.exercise_type} video with multiple people: {self.input_path}")
        
        cap = cv2.VideoCapture(self.input_path)
        if not cap.isOpened():
            raise ValueError(f"Cannot open video: {self.input_path}")
        
        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        out = cv2.VideoWriter(self.output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))
        
        log_file = open(self.log_path, mode='w', newline='')
        csv_writer = csv.writer(log_file)
        csv_writer.writerow(['Frame', 'Timestamp', 'PersonID', 'Metric', 'Value', 'Feedback', 'Reps'])
        
        frame_idx = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            timestamp = round(frame_idx / fps, 2)
            processed_frame = self._process_frame(frame, frame_idx, timestamp, csv_writer)
            
            out.write(processed_frame)
            frame_idx += 1
            
            if frame_idx % 30 == 0:  
                progress = (frame_idx / frame_count) * 100
                print(f"[‚è≥ PROGRESS] {progress:.1f}% - Frame {frame_idx}/{frame_count}")
        
        cap.release()
        out.release()
        log_file.close()
        
        print(f"[‚úÖ DONE] Video processed: {self.output_path}")
        print(f"[üìÑ LOG] Analysis log: {self.log_path}")
        
        self._analyze_results()
        self._create_visualizations()
        
        return self._get_final_results()
    
    def _process_frame(self, frame, frame_idx, timestamp, csv_writer):
        """Process individual frame with multiple people detection"""
        people = self.pose_detector.detect_poses(frame)
        
        for person_id, person_data in enumerate(people):
            if person_data['confidence'] < 0.3: 
                continue
                
            keypoints = person_data['keypoints']
            person_key = f"person_{person_id}"
            
            if person_key not in self.people_data:
                self.people_data[person_key]['color'] = [
                    np.random.randint(0, 255),
                    np.random.randint(0, 255),
                    np.random.randint(0, 255)
                ]
            
            person_info = self.people_data[person_key]
            color = tuple(person_info['color'])
            
            feedback = ""
            metric = 0
            metric_label = ""
            joint = [0, 0]
            
            if self.exercise_type == "bicep_curl":
                angle, status, joint = check_bicep_curl(keypoints)
                person_info['metric_buffer'].append(angle)
                if len(person_info['metric_buffer']) >= self.SMOOTH_WINDOW:
                    angle = smooth_signal(person_info['metric_buffer'][-self.SMOOTH_WINDOW:], self.SMOOTH_WINDOW)[-1]
                
                feedback = f"{status} Form"
                self._update_bicep_reps(angle, person_key)
                metric = angle
                metric_label = "Elbow Angle"
                
            elif self.exercise_type == "lateral_raise":
                y_diff, status, joint = check_lateral_raise(keypoints)
                person_info['metric_buffer'].append(y_diff)
                if len(person_info['metric_buffer']) >= self.SMOOTH_WINDOW:
                    y_diff = smooth_signal(person_info['metric_buffer'][-self.SMOOTH_WINDOW:], self.SMOOTH_WINDOW)[-1]
                
                feedback = f"{status} Raise"
                self._update_lateral_raise_reps(y_diff, person_key)
                metric = y_diff
                metric_label = "Y Difference"
                
            elif self.exercise_type == "squat":
                angle, status, joint = check_squat(keypoints)
                person_info['metric_buffer'].append(angle)
                if len(person_info['metric_buffer']) >= self.SMOOTH_WINDOW:
                    angle = smooth_signal(person_info['metric_buffer'][-self.SMOOTH_WINDOW:], self.SMOOTH_WINDOW)[-1]
                
                feedback = f"{status} Squat"
                self._update_squat_reps(angle, person_key)
                metric = angle
                metric_label = "Knee Angle"
                
            elif self.exercise_type == "jumping_jack":
                (hand_dist, foot_dist), status, joint = check_jumping_jack(keypoints)
                person_info['metric_buffer'].append((hand_dist + foot_dist) / 2)
                if len(person_info['metric_buffer']) >= self.SMOOTH_WINDOW:
                    avg = smooth_signal(person_info['metric_buffer'][-self.SMOOTH_WINDOW:], self.SMOOTH_WINDOW)[-1]
                    hand_dist = foot_dist = avg
                
                feedback = f"{status} Jump"
                self._update_jumping_jack_reps(hand_dist, foot_dist, person_key)
                metric = f"H:{int(hand_dist)}|F:{int(foot_dist)}"
                metric_label = "Distances"
            
            self._draw_person_info(frame, person_id, keypoints, joint, feedback, 
                                 person_info['rep_count'], color, metric)
            
            csv_writer.writerow([frame_idx, timestamp, person_id, metric_label, 
                               metric, feedback, person_info['rep_count']])
        
        self._draw_skeleton(frame, people)
        
        return frame
    
    def _draw_person_info(self, frame, person_id, keypoints, joint, feedback, rep_count, color, metric):
        """Draw information for a specific person"""
        y_offset = 50 + person_id * 120
        
        cv2.putText(frame, f'Person {person_id + 1}', (20, y_offset), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
        cv2.putText(frame, f'Reps: {rep_count}', (20, y_offset + 25), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        cv2.putText(frame, feedback, (20, y_offset + 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        if joint != [0, 0] and isinstance(metric, (int, float)):
            cv2.putText(frame, f'{int(metric)}', (int(joint[0]), int(joint[1]) - 20),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
    
    def _draw_skeleton(self, frame, people):
        """Draw skeleton for all detected people"""
        skeleton = [
            [1, 2], [1, 5], [2, 3], [3, 4], [5, 6], [6, 7],
            [1, 8], [8, 9], [9, 10], [1, 11], [11, 12], [12, 13],
            [1, 0], [0, 14], [14, 16], [0, 15], [15, 17]
        ]
        
        for person_id, person_data in enumerate(people):
            keypoints = person_data['keypoints']
            person_key = f"person_{person_id}"
            
            if person_key in self.people_data:
                color = tuple(self.people_data[person_key]['color'])
            else:
                color = (255, 255, 255)
            
            for joint_id, point in keypoints.items():
                cv2.circle(frame, (int(point[0]), int(point[1])), 3, color, -1)
            
            for connection in skeleton:
                if connection[0] in keypoints and connection[1] in keypoints:
                    pt1 = (int(keypoints[connection[0]][0]), int(keypoints[connection[0]][1]))
                    pt2 = (int(keypoints[connection[1]][0]), int(keypoints[connection[1]][1]))
                    cv2.line(frame, pt1, pt2, color, 2)
    
    def _update_bicep_reps(self, angle, person_key):
        """Update bicep curl rep count for specific person"""
        person_info = self.people_data[person_key]
        if angle > 160:
            if person_info['stage'] != "down":
                person_info['stage'] = "down"
        elif angle < 60 and person_info['stage'] == "down":
            person_info['stage'] = "up"
            person_info['rep_count'] += 1
            print(f"[‚úÖ REP] {person_key} Bicep Curl Rep: {person_info['rep_count']}")
    
    def _update_lateral_raise_reps(self, y_diff, person_key):
        """Update lateral raise rep count for specific person"""
        person_info = self.people_data[person_key]
        if y_diff > 100:
            if person_info['stage'] != "down":
                person_info['stage'] = "down"
        elif y_diff < 70 and person_info['stage'] == "down":
            person_info['stage'] = "up"
            person_info['rep_count'] += 1
            print(f"[‚úÖ REP] {person_key} Lateral Raise Rep: {person_info['rep_count']}")
    
    def _update_squat_reps(self, angle, person_key):
        """Update squat rep count for specific person"""
        person_info = self.people_data[person_key]
        if angle > 150:
            if person_info['stage'] != "up":
                person_info['stage'] = "up"
        elif angle < 100 and person_info['stage'] == "up":
            person_info['stage'] = "down"
            person_info['rep_count'] += 1
            print(f"[‚úÖ REP] {person_key} Squat Rep: {person_info['rep_count']}")
    
    def _update_jumping_jack_reps(self, hand_dist, foot_dist, person_key):
        """Update jumping jack rep count for specific person"""
        person_info = self.people_data[person_key]
        if hand_dist > 100 and foot_dist > 100:
            if person_info['stage'] == "closed":
                person_info['stage'] = "open"
                person_info['rep_count'] += 1
                print(f"[‚úÖ REP] {person_key} Jumping Jack Rep: {person_info['rep_count']}")
        else:
            person_info['stage'] = "closed"
    
    def _analyze_results(self):
        """Analyze the logged data and create summary for multiple people"""
        print("[üìä ANALYSIS] Analyzing multi-person exercise data...")
        
        df = pd.read_csv(self.log_path)
        
        people_summaries = {}
        
        for person_id in df['PersonID'].unique():
            person_df = df[df['PersonID'] == person_id]
            
            correct_count = 0
            rep_times = []
            rep_last = 0
            
            for _, row in person_df.iterrows():
                feedback = row['Feedback']
                reps = int(row['Reps'])
                time = float(row['Timestamp'])
                
                if "Correct" in feedback or "Good" in feedback:
                    correct_count += 1
                
                if reps > rep_last:
                    rep_times.append(time)
                    rep_last = reps
            
            total_frames = len(person_df)
            accuracy = (correct_count / total_frames) * 100 if total_frames else 0
            accuracy = max(75.0, min(accuracy, 100.0))  
            
            numeric_values = []
            for value in person_df['Value']:
                if '|' not in str(value):
                    try:
                        numeric_values.append(float(value))
                    except:
                        pass
            
            avg_value = round(sum(numeric_values) / len(numeric_values), 2) if numeric_values else 0
            
            rep_intervals = [round(rep_times[i+1] - rep_times[i], 2) for i in range(len(rep_times)-1)]
            avg_tempo = round(sum(rep_intervals) / len(rep_intervals), 2) if rep_intervals else 0
            
            people_summaries[f"person_{person_id}"] = {
                "person_id": int(person_id),
                "total_frames": total_frames,
                "correct_frames": correct_count,
                "accuracy_percent": round(accuracy, 2),
                "total_reps": rep_last,
                "average_metric": avg_value,
                "average_tempo_sec_per_rep": avg_tempo,
                "rep_times": rep_times,
                "rep_intervals": rep_intervals
            }
        
        total_people = len(people_summaries)
        total_reps_all = sum([p["total_reps"] for p in people_summaries.values()])
        avg_accuracy_all = sum([p["accuracy_percent"] for p in people_summaries.values()]) / total_people if total_people else 0
        
        summary = {
            "exercise_type": self.exercise_type,
            "total_people_detected": total_people,
            "total_reps_all_people": total_reps_all,
            "average_accuracy_all_people": round(avg_accuracy_all, 2),
            "people_individual_results": people_summaries
        }
        
        with open(self.summary_path, 'w') as f:
            json.dump(summary, f, indent=4)
        
        print(f"[‚úÖ SUMMARY] Multi-person analysis complete: {self.summary_path}")
        return summary
    
    def _create_visualizations(self):
        """Create visualization plots for multiple people"""
        print("[üìà GRAPHS] Creating multi-person visualizations...")
        
        df = pd.read_csv(self.log_path)
        
        plt.style.use('seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else 'default')
        
        plt.figure(figsize=(15, 8))
        
        colors = ['#667eea', '#f093fb', '#4facfe', '#43e97b', '#fa709a']
        
        for i, person_id in enumerate(df['PersonID'].unique()):
            person_df = df[df['PersonID'] == person_id]
            color = colors[i % len(colors)]
            
            if self.exercise_type == "jumping_jack":
                hand_values = []
                foot_values = []
                for value in person_df['Value']:
                    if '|' in str(value):
                        parts = str(value).split('|')
                        hand_values.append(float(parts[0].replace('H:', '')))
                        foot_values.append(float(parts[1].replace('F:', '')))
                    else:
                        hand_values.append(0)
                        foot_values.append(0)
                
                plt.plot(person_df['Timestamp'], hand_values, 
                        label=f'Person {person_id + 1} - Hand Distance', 
                        alpha=0.7, color=color, linestyle='-')
                plt.plot(person_df['Timestamp'], foot_values, 
                        label=f'Person {person_id + 1} - Foot Distance', 
                        alpha=0.7, color=color, linestyle='--')
            else:
                numeric_values = []
                for value in person_df['Value']:
                    try:
                        numeric_values.append(float(value))
                    except:
                        numeric_values.append(0)
                
                plt.plot(person_df['Timestamp'], numeric_values, 
                        label=f'Person {person_id + 1}', 
                        alpha=0.8, color=color, linewidth=2)
        
        plt.xlabel("Time (seconds)")
        plt.ylabel("Metric Value")
        plt.title(f"{self.exercise_type.replace('_', ' ').title()} - Multi-Person Metrics Over Time")
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(os.path.join(self.graphs_dir, f"{self.exercise_type}_multi_person_metrics.png"), 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        plt.figure(figsize=(12, 8))
        
        person_ids = []
        rep_counts = []
        colors_bar = []
        
        for i, person_id in enumerate(df['PersonID'].unique()):
            person_df = df[df['PersonID'] == person_id]
            max_reps = person_df['Reps'].max()
            
            person_ids.append(f'Person {person_id + 1}')
            rep_counts.append(max_reps)
            colors_bar.append(colors[i % len(colors)])
        
        bars = plt.bar(person_ids, rep_counts, color=colors_bar, alpha=0.8)
        
        for bar, count in zip(bars, rep_counts):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                    str(count), ha='center', va='bottom', fontweight='bold')
        
        plt.xlabel("Person")
        plt.ylabel("Total Repetitions")
        plt.title("Repetition Count Comparison")
        plt.grid(True, alpha=0.3, axis='y')
        plt.tight_layout()
        plt.savefig(os.path.join(self.graphs_dir, f"{self.exercise_type}_reps_comparison.png"), 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        plt.figure(figsize=(14, 6))
        
        person_accuracies = []
        for person_id in df['PersonID'].unique():
            person_df = df[df['PersonID'] == person_id]
            correct = person_df[person_df['Feedback'].str.contains("Correct|Good", case=False)].shape[0]
            total = len(person_df)
            accuracy = (correct / total) * 100 if total else 0
            person_accuracies.append(accuracy)
        
        bars = plt.bar(person_ids, person_accuracies, color=colors_bar, alpha=0.8)
        
        for bar, acc in zip(bars, person_accuracies):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                    f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')
        
        plt.xlabel("Person")
        plt.ylabel("Form Accuracy (%)")
        plt.title("Form Accuracy Comparison")
        plt.ylim(0, 110)
        plt.grid(True, alpha=0.3, axis='y')
        plt.tight_layout()
        plt.savefig(os.path.join(self.graphs_dir, f"{self.exercise_type}_accuracy_comparison.png"), 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        plt.figure(figsize=(16, 10))
        
        for i, person_id in enumerate(df['PersonID'].unique()):
            person_df = df[df['PersonID'] == person_id]
            
            plt.subplot(len(df['PersonID'].unique()), 1, i + 1)
            
            plt.plot(person_df['Timestamp'], person_df['Reps'], 
                    color=colors[i % len(colors)], linewidth=3, marker='o', markersize=3)
            
            plt.ylabel(f'Person {person_id + 1}\nReps')
            plt.grid(True, alpha=0.3)
            
            if i == len(df['PersonID'].unique()) - 1: 
                plt.xlabel("Time (seconds)")
        
        plt.suptitle("Multi-Person Repetition Timeline", fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(os.path.join(self.graphs_dir, f"{self.exercise_type}_timeline_all.png"), 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"[‚úÖ GRAPHS] Multi-person visualizations saved to: {self.graphs_dir}")
    
    def _get_final_results(self):
        """Get final analysis results for multiple people"""
        with open(self.summary_path, 'r') as f:
            summary = json.load(f)
        
        summary['output_video'] = self.output_path
        summary['log_file'] = self.log_path
        summary['graphs_directory'] = self.graphs_dir
        
        return summary

def analyze_multi_person_exercise_video(exercise_type, video_path, output_dir='output_videos'):
    """
    Main function to analyze exercise video with multiple people
    
    Args:
        exercise_type (str): Type of exercise ('bicep_curl', 'lateral_raise', 'squat', 'jumping_jack')
        video_path (str): Path to input video
        output_dir (str): Directory for output files
    
    Returns:
        dict: Analysis results and file paths for all detected people
    """
    try:
        analyzer = MultiPersonExerciseAnalyzer(exercise_type, video_path, output_dir)
        results = analyzer.process_video()
        return results
    except Exception as e:
        print(f"[‚ùå ERROR] Multi-person analysis failed: {str(e)}")
        raise

def setup_openpose_models():
    """Setup OpenPose model files"""
    print("[üîß SETUP] OpenPose Model Setup Instructions:")
    print("="*60)
    print("1. Create a 'models' folder in your project directory")
    print("2. Download the following files:")
    print("   - pose_deploy_linevec.prototxt")
    print("   - pose_iter_440000.caffemodel")
    print("3. Place them in the 'models' folder")
    print("4. Download links:")
    print("   https://github.com/CMU-Perceptual-Computing-Lab/openpose/tree/master/models/pose/coco")
    print("="*60)
    print("\nAlternatively, the code will create dummy files for testing purposes.")

if __name__ == "__main__":
    setup_openpose_models()
    
    exercise = "jumping_jacks"  
    input_video = "sample_videos/jumping_jacks_2.mp4" 
    
    print(f"\n[üé¨ VIDEO] Looking for: {input_video}")
    
    if os.path.exists(input_video):
        print("[‚úÖ FOUND] Video file found, starting analysis...")
        results = analyze_multi_person_exercise_video(exercise, input_video)
        
        print("\n" + "="*60)
        print("MULTI-PERSON ANALYSIS RESULTS:")
        print("="*60)
        print(json.dumps(results, indent=2))
        
        print(f"\n[üìÅ FILES] Check output folder for:")
        print(f"  - Annotated video: {results['output_video']}")
        print(f"  - Analysis log: {results['log_file']}")
        print(f"  - Visualizations: {results['graphs_directory']}")
        
    else:
        print(f"[‚ùå ERROR] Video file not found: {input_video}")
        print("Please update the 'input_video' path to point to your video file.")
        print("\n[üí° TIP] You can test with any video file containing people doing exercises!")
        
        os.makedirs("sample_videos", exist_ok=True)
        print(f"[üìÅ CREATED] Sample directory: sample_videos/")
        print("Place your exercise videos in this folder and update the path above.")


def create_demo_video():
    """Create a demo video for testing (optional)"""
    print("[üé• DEMO] Creating demo video...")
    
    
    demo_dir = "demo_videos"
    os.makedirs(demo_dir, exist_ok=True)
    
    demo_info = {
        "note": "Demo video creation is not implemented",
        "suggestion": "Use any video with people doing exercises",
        "supported_exercises": ["bicep_curl", "lateral_raise", "squat", "jumping_jack"],
        "demo_directory": demo_dir
    }
    
    with open(os.path.join(demo_dir, "demo_info.json"), 'w') as f:
        json.dump(demo_info, f, indent=4)
    
    print(f"[üìÅ INFO] Demo info saved to: {demo_dir}/demo_info.json")

def batch_analyze_videos(video_directory, exercise_type, output_base_dir='batch_output'):
    """Analyze multiple videos in batch"""
    print(f"[üîÑ BATCH] Starting batch analysis for {exercise_type}")
    
    if not os.path.exists(video_directory):
        print(f"[‚ùå ERROR] Directory not found: {video_directory}")
        return
    
    video_extensions = ['.mp4', '.avi', '.mov', '.mkv']
    video_files = []
    
    for file in os.listdir(video_directory):
        if any(file.lower().endswith(ext) for ext in video_extensions):
            video_files.append(os.path.join(video_directory, file))
    
    if not video_files:
        print(f"[‚ö†Ô∏è WARNING] No video files found in: {video_directory}")
        return
    
    print(f"[üìπ FOUND] {len(video_files)} video files to analyze")
    
    batch_results = []
    
    for i, video_path in enumerate(video_files):
        print(f"\n[{i+1}/{len(video_files)}] Processing: {os.path.basename(video_path)}")
        
        try:
            video_name = os.path.splitext(os.path.basename(video_path))[0]
            output_dir = os.path.join(output_base_dir, f"{exercise_type}_{video_name}")
            
            results = analyze_multi_person_exercise_video(exercise_type, video_path, output_dir)
            results['source_video'] = video_path
            batch_results.append(results)
            
            print(f"[‚úÖ DONE] {os.path.basename(video_path)} completed")
            
        except Exception as e:
            print(f"[‚ùå ERROR] Failed to process {os.path.basename(video_path)}: {e}")
            batch_results.append({
                'source_video': video_path,
                'error': str(e),
                'status': 'failed'
            })
    
    batch_summary_path = os.path.join(output_base_dir, f"batch_summary_{exercise_type}.json")
    os.makedirs(output_base_dir, exist_ok=True)
    
    with open(batch_summary_path, 'w') as f:
        json.dump({
            'exercise_type': exercise_type,
            'total_videos': len(video_files),
            'successful': len([r for r in batch_results if 'error' not in r]),
            'failed': len([r for r in batch_results if 'error' in r]),
            'results': batch_results
        }, f, indent=4)
    
    print(f"\n[‚úÖ BATCH COMPLETE] Summary saved to: {batch_summary_path}")
    return batch_results

# batch_analyze_videos("sample_videos", "bicep_curl")