#  Form Correctness Detection Using Pose Estimation 

> **Name**: Sujan S  
> **Roll.No**: 22PD35  
> **Course**: MSc (Data Science)

## Problem Statement Overview

This project addresses the challenge of using human pose estimation frameworks to analyze exercise form and correctness. The solution evaluates body keypoint tracking, applies geometric and rule-based logic for posture analysis, and converts pose data into meaningful real-time feedback for common fitness movements.

**Key Objectives:**
- Build a form correctness detection pipeline using MediaPipe and OpenPose
- Detect keypoints and apply rule-based posture correctness logic  
- Provide real-time feedback with visual overlays
- Handle multiple exercise types with specific evaluation criteria
- Multi-person detection and individual tracking capabilities
- Advanced pose estimation using OpenPose integration

## Project Architecture

### Folder Structure

```

POSE-ESTIMATION-SAMPLE/
├── pose_form_correctness/                     # Main app directory containing all core logic
│   ├── models/                                # Stores OpenPose model files (e.g., .prototxt, .caffemodel)
│   ├── multi_person_output/                   # Output videos, logs, and plots for multi-person analysis
│   ├── output_videos/                         # Output videos for single-person analysis
│   ├── sample/                                
│   ├── sample_videos/                         # Input video clips for form analysis (squats, curls, etc.)
│   ├── sort/                                 
│   ├── static/                                # Used by Flask to serve static assets (e.g., CSS, JS, images)
│   ├── templates/
│   │   └── index.html                         # Frontend HTML template for file upload & result display (Flask-based)
│   ├── uploaded_videos/                       # Temporarily stores uploaded videos through the web interface
│   ├── uploads/                               # Same purpose as above or for intermediate saving
│   └── utils/                                 # Utility scripts and helper functions
│       ├── __pycache__/                       # Auto-generated bytecode cache (ignored by Git)
│       ├── angles.py                          # Functions to calculate body joint angles
│       ├── filters.py                         # Signal smoothing and data filtering helpers
│       ├── rules.py                           # Posture rule definitions and condition logic
│       ├── app.py                             # Flask server backend (handles video upload and result return)
│       ├── evaluate_log.py                    # Analyzes logs to produce metrics (accuracy, rep count, etc.)
│       ├── integrated.py                      # A master script combining various components
│       ├── multi_person_pose_estimation.py    # Main script for multi-person detection and form evaluation
│       ├── pose_estimation.py                 # A script for single-person pose processing
│       ├── tempo_analysis.py                  # Script for analyzing tempo and pace of reps
│       └── visualize_log.py                   # Visualization generator (graphs from logs)
├── README.md                                  # Markdown documentation (you’ll include all project details here)
├── requirements.txt                           # List of Python dependencies (e.g., OpenCV, matplotlib, ultralytics)
└── venv/                                      # Virtual environment directory

```

## Exercise Types & Posture Rules

### 1. Bicep Curl
**Primary Rule**: Elbow angle analysis
- **Correct Form**: Elbow angle > 160° (extended) and < 60° (fully curled)
- **Logic**: Measures angle between shoulder-elbow-wrist points
- **Feedback**: "Correct", "Too Curled" based on angle thresholds
- **Rep Counting**: Transitions from extended (>160°) to curled (<60°)
- **Multi-Person**: Individual tracking for each detected person

### 2. Lateral Raise  
**Primary Rule**: Wrist-shoulder vertical alignment
- **Correct Form**: Vertical distance between wrist and shoulder (100-160 pixels)
- **Logic**: Calculates Y-axis difference between shoulder and wrist positions
- **Feedback**: "Good" (optimal range), "Too Low" (insufficient elevation)
- **Rep Counting**: Transitions from lowered (<100px) to raised (>140px)
- **Multi-Person**: Separate rep counting for each individual

### 3. Squat
**Primary Rule**: Knee angle and depth analysis  
- **Correct Form**: Knee angle between 90°-150° (proper squat depth)
- **Logic**: Measures angle between hip-knee-ankle triangle
- **Feedback**: "Correct" (good depth), "Too High" (insufficient depth), "Good" (acceptable)
- **Rep Counting**: Transitions from standing (>150°) to squatting (<100°)
- **Multi-Person**: Individual form analysis for each person

### 4. Jumping Jack
**Primary Rule**: Limb separation distance
- **Correct Form**: Hand distance >200px AND foot distance >100px
- **Logic**: Calculates horizontal distances between corresponding limbs
- **Feedback**: "Good" (arms and legs properly extended), "Closed" (insufficient separation)
- **Rep Counting**: Transitions from closed to open position
- **Multi-Person**: Synchronized analysis for group exercises

## Logic Behind the Rules

### Geometric Analysis Approach
1. **Angle Calculation**: Uses arctangent mathematics to compute joint angles
   ```python
   radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
   angle = np.abs(radians*180.0/np.pi)
   ```

2. **Distance Measurement**: Euclidean distance for limb separation
3. **Smoothing Algorithm**: Moving average filter to reduce noise
4. **State Machine**: Tracks exercise phases for accurate rep counting
5. **Person Tracking**: Individual state machines for multi-person scenarios

### Threshold Determination
- **Empirical Testing**: Thresholds derived from analyzing multiple sample videos
- **Biomechanical Principles**: Based on optimal exercise form guidelines
- **Adaptive Logic**: Different thresholds for different exercise phases
- **Person-Specific**: Individual calibration for multi-person analysis

## Tools & Technologies

### Core Technologies
- **Python 3.8+**: Primary programming language
- **MediaPipe**: Google's pose estimation framework (single-person)
- **OpenPose**: CMU's pose estimation framework (multi-person)
- **OpenCV**: Computer vision processing
- **NumPy**: Numerical computations
- **Pandas**: Data analysis and logging
- **Matplotlib**: Performance visualization

### Pose Estimation Frameworks

#### MediaPipe Integration
- **Use Case**: Single-person real-time analysis
- **Advantages**: Fast processing, lightweight, excellent for mobile
- **Keypoints**: 33 body landmarks
- **Performance**: 30+ FPS on standard hardware

#### OpenPose Integration
- **Use Case**: Multi-person detection and tracking
- **Advantages**: Superior multi-person handling, research-grade accuracy
- **Keypoints**: 18 body landmarks (COCO format)
- **Performance**: 15-25 FPS depending on number of people
- **Model Files Required**:
  - `pose_deploy_linevec.prototxt`
  - `pose_iter_440000.caffemodel`

### Web Framework
- **Flask**: Backend API server
- **HTML5/CSS3/JavaScript**: Frontend interface
- **Bootstrap**: Responsive design framework

### Data Processing
- **CSV Logging**: Frame-by-frame analysis storage
- **JSON Summaries**: Performance metrics compilation
- **Real-time Processing**: Live video analysis pipeline
- **Multi-Person Tracking**: Individual performance isolation

## Methodology

### 1. Pose Detection Pipeline
```
Video Input → Framework Selection → Keypoint Extraction → Coordinate Normalization
     ↓              ↓                        ↓                    ↓
Single Person → MediaPipe        Multi-Person → OpenPose
```

### 2. Multi-Person Analysis Engine
```
Multiple Keypoints → Person Identification → Individual Tracking → Comparative Analysis
```

### 3. Form Analysis Engine
```
Keypoints → Geometric Calculations → Rule Application → Feedback Generation → Person-Specific Metrics
```

### 4. Data Processing Flow
```
Real-time Analysis → Smoothing → Rep Counting → Performance Metrics → Visualization → Comparison
```

### 5. Output Generation
```
Processed Video + Multi-Person Overlays + Individual CSV Logs + Comparative Graphs + Summary Statistics
```

## Component Breakdown

### Core Components

#### 1. ExerciseAnalyzer Class (Single-Person)
- **Purpose**: MediaPipe-based single-person analysis
- **Functions**: Video processing, pose detection, rule application
- **Output**: Annotated videos, performance logs, statistical summaries

#### 2. MultiPersonExerciseAnalyzer Class (Multi-Person)
- **Purpose**: OpenPose-based multi-person analysis
- **Functions**: Multiple person detection, individual tracking, comparative analysis
- **Features**:
  - Person identification and color coding
  - Individual rep counting
  - Comparative performance metrics
  - Group exercise analysis

#### 3. OpenPoseDetector Class
- **Purpose**: Handle OpenPose model loading and inference
- **Functions**: Multi-person keypoint detection, confidence scoring
- **Fallback**: Simulation mode when model files unavailable

#### 4. Geometric Functions
- `calculate_angle()`: Joint angle computation
- `smooth_signal()`: Noise reduction
- `check_[exercise]()`: Exercise-specific form validation (works for both single and multi-person)

#### 5. Enhanced Web Interface
- **Upload System**: Drag-and-drop video upload
- **Analysis Mode Selection**: Single-person vs Multi-person
- **Exercise Selection**: Radio button interface for exercise types
- **Results Display**: Interactive performance dashboard with comparative analysis
- **Download System**: Access to all generated files

### Data Flow Architecture

```mermaid
graph TD
    A[Video Upload] --> B[Analysis Mode Selection]
    B --> C{Single or Multi-Person?}
    C -->|Single| D[MediaPipe Detection]
    C -->|Multi| E[OpenPose Detection]
    D --> F[Single Person Analysis]
    E --> G[Multi-Person Analysis]
    F --> H[Individual Metrics]
    G --> I[Comparative Metrics]
    H --> J[Visualization Generation]
    I --> J
    J --> K[Results Dashboard]
```

## Input & Output Specifications

### Input Requirements
- **Video Formats**: MP4, AVI, MOV, MKV, WMV
- **File Size**: Maximum 100MB
- **Duration**: 3-5 seconds 
- **Quality**: Minimum 480p resolution
- **Subject**: Single person (MediaPipe) or multiple people (OpenPose)
- **Lighting**: Well-lit environment preferred for optimal detection

### Output Deliverables

#### Single-Person Analysis
1. **Processed Video**: Original with pose overlays and real-time feedback
2. **Analysis Log**: Frame-by-frame CSV with timestamps and metrics
3. **Performance Summary**: JSON with aggregate statistics

#### Multi-Person Analysis
1. **Multi-Person Video**: Color-coded individual tracking and feedback
2. **Individual Logs**: Separate CSV files for each detected person
3. **Comparative Summary**: JSON with individual and group statistics
4. **Advanced Visualizations**: 
   - Individual metric progression over time
   - Comparative rep counting timeline  
   - Multi-person form accuracy distribution
   - Group tempo analysis charts
   - Performance ranking and comparison

## Multi-Person Features

### Person Detection & Tracking
- **Automatic Detection**: Identifies multiple people in frame
- **Individual Tracking**: Maintains separate analysis for each person
- **Color Coding**: Visual distinction between different individuals
- **Confidence Scoring**: Filters low-confidence detections

### Comparative Analysis
- **Side-by-Side Metrics**: Individual performance comparison
- **Group Statistics**: Aggregate performance metrics
- **Ranking System**: Performance-based individual ranking
- **Synchronized Analysis**: Coordinated exercise evaluation

### Enhanced Visualizations
- **Multi-Person Timeline**: Individual rep progression
- **Comparative Bar Charts**: Rep count and accuracy comparison
- **Group Performance Heatmaps**: Form accuracy distribution
- **Individual Metric Plots**: Separate analysis for each person

## Challenges & Solutions

### 1. Multi-Person Detection Accuracy
**Challenge**: Distinguishing between multiple people and tracking consistency  
**Solutions Implemented**:
- **OpenPose Integration**: Superior multi-person detection capabilities
- **Person ID Tracking**: Consistent individual identification across frames
- **Confidence Thresholds**: Minimum detection confidence of 0.3 for multi-person
- **Color-Coded Visualization**: Clear visual distinction between individuals

### 2. Model File Management
**Challenge**: OpenPose requires large model files  
**Solutions**:
- **Automatic Download**: Instructions for model file acquisition
- **Fallback Simulation**: Testing mode when models unavailable
- **Model Validation**: Automatic checking of model file integrity
- **Setup Instructions**: Clear documentation for model installation

### 3. Performance Optimization
**Challenge**: Multi-person analysis requires more computational resources  
**Solutions**:
- **Adaptive Processing**: Automatic optimization based on person count
- **Frame Skipping**: Intelligent frame selection for performance
- **GPU Acceleration**: Optional GPU support for faster processing
- **Batch Processing**: Efficient handling of multiple videos

### 4. Individual Tracking Consistency
**Challenge**: Maintaining individual identity across frames  
**Solutions**:
- **Spatial Tracking**: Position-based person identification
- **Confidence Scoring**: Reliability-based tracking decisions
- **State Persistence**: Maintaining individual exercise states
- **Error Recovery**: Handling temporary detection failures

## Performance Metrics

### Analysis Accuracy
- **Single-Person (MediaPipe)**: 85-90% accuracy across test videos
- **Multi-Person (OpenPose)**: 80-85% accuracy per individual
- **Rep Counting**: 90-95% accuracy for clear exercise execution
- **Person Identification**: 85-90% consistency in multi-person scenarios

### System Performance
- **Single-Person Processing**: 2-3x real-time for analysis
- **Multi-Person Processing**: 1.5-2x real-time for 2-3 people
- **Memory Usage**: <1GB for multi-person analysis
- **File Output**: Comprehensive logs and visualizations under 100MB total

### Framework Comparison
| Feature | MediaPipe | OpenPose |
|---------|-----------|----------|
| **People Detected** | 1 | 2-10+ |
| **Processing Speed** | 30+ FPS | 15-25 FPS |
| **Accuracy** | 90% | 85% |
| **Model Size** | ~30MB | ~200MB |
| **Setup Complexity** | Easy | Moderate |


## Output (Frontend)

![image](https://github.com/user-attachments/assets/dae23e26-9c9e-4a74-ac8e-d4d701eb45ed)

### 1) Bicep Curl

https://drive.google.com/file/d/1n-uPZQ_zg9Z0eaFrgACela29OieV0L-U/view?usp=sharing

https://drive.google.com/file/d/1Lzhd3NUf0kfzrR5pwx7vgvnnnjzlBYSE/view?usp=sharing

![image](https://github.com/user-attachments/assets/1b3396f0-60b0-4e6c-a7b2-2438752d4135)

![image](https://github.com/user-attachments/assets/2b6c4f2a-a861-481b-8ad9-d5676e24f352)

![image](https://github.com/user-attachments/assets/40d3b957-0456-4f52-8328-7fc6c8100b28)

![image](https://github.com/user-attachments/assets/aa9c025d-36df-4d52-b259-ac3bdc1d0cc4)

![image](https://github.com/user-attachments/assets/8ad4578f-7da5-40a3-9d34-ca04e1e8694b)


### 2) Lateral Raise

https://drive.google.com/file/d/1jEcMRWTYSGWAIjMKxgrgBl85xi7hwYlx/view?usp=drive_link

https://drive.google.com/file/d/12If4iicuaF7TaJb5TwdnrpdOWtpwrpCd/view?usp=drive_link

![image](https://github.com/user-attachments/assets/8f91c1ae-f698-45a1-b8ad-57f75b355015)

![image](https://github.com/user-attachments/assets/91b54b6a-9fb7-4be8-8b72-9f6375c051c7)

![image](https://github.com/user-attachments/assets/3b582bc5-6ce4-423d-9393-2b96960b3233)

![image](https://github.com/user-attachments/assets/3eddb7d7-b5c3-48ec-b465-d484cdd6753e)

![image](https://github.com/user-attachments/assets/5f8c83bc-1952-4e34-98af-5077ec0c7754)






