#  Form Correctness Detection Using Pose Estimation 

> **Name**: Sujan S  
> **Roll.No**: 22PD35  
> **Course**: MSc (Data Science)

## Video Explaination



## Problem Statement Overview

This project addresses the challenge of using human pose estimation frameworks to analyze exercise form and correctness. The solution evaluates body keypoint tracking, applies geometric and rule-based logic for posture analysis, and converts pose data into meaningful real-time feedback for common fitness movements.

**Key Objectives:**
- Build a form correctness detection pipeline using MediaPipe and OpenPose
- Detect keypoints and apply rule-based posture correctness logic  
- Provide real-time feedback with visual overlays
- Handle multiple exercise types with specific evaluation criteria
- Multi-person detection and individual tracking capabilities
- Advanced pose estimation using OpenPose integration

## Project Architecture

### Folder Structure

```

POSE-ESTIMATION-SAMPLE/
├── pose_form_correctness/                     # Main app directory containing all core logic
│   ├── models/                                # Stores OpenPose model files (e.g., .prototxt, .caffemodel)
│   ├── multi_person_output/                   # Output videos, logs, and plots for multi-person analysis
│   ├── output_videos/                         # Output videos for single-person analysis
│   ├── sample/                                
│   ├── sample_videos/                         # Input video clips for form analysis (squats, curls, etc.)
│   ├── sort/                                 
│   ├── static/                                # Used by Flask to serve static assets (e.g., CSS, JS, images)
│   ├── templates/
│   │   └── index.html                         # Frontend HTML template for file upload & result display (Flask-based)
│   ├── uploaded_videos/                       # Temporarily stores uploaded videos through the web interface
│   ├── uploads/                               # Same purpose as above or for intermediate saving
│   └── utils/                                 # Utility scripts and helper functions
│       ├── __pycache__/                       # Auto-generated bytecode cache (ignored by Git)
│       ├── angles.py                          # Functions to calculate body joint angles
│       ├── filters.py                         # Signal smoothing and data filtering helpers
│       ├── rules.py                           # Posture rule definitions and condition logic
│       ├── app.py                             # Flask server backend (handles video upload and result return)
│       ├── evaluate_log.py                    # Analyzes logs to produce metrics (accuracy, rep count, etc.)
│       ├── integrated.py                      # A master script combining various components
│       ├── multi_person_pose_estimation.py    # Main script for multi-person detection and form evaluation
│       ├── pose_estimation.py                 # A script for single-person pose processing
│       ├── tempo_analysis.py                  # Script for analyzing tempo and pace of reps
│       └── visualize_log.py                   # Visualization generator (graphs from logs)
├── README.md                                  # Markdown documentation (you’ll include all project details here)
├── requirements.txt                           # List of Python dependencies (e.g., OpenCV, matplotlib, ultralytics)
└── venv/                                      # Virtual environment directory

```

## Exercise Types & Posture Rules

### 1. Bicep Curl
**Primary Rule**: Elbow angle analysis
- **Correct Form**: Elbow angle > 160° (extended) and < 60° (fully curled)
- **Logic**: Measures angle between shoulder-elbow-wrist points
- **Feedback**: "Correct", "Too Curled" based on angle thresholds
- **Rep Counting**: Transitions from extended (>160°) to curled (<60°)
- **Multi-Person**: Individual tracking for each detected person

### 2. Lateral Raise  
**Primary Rule**: Wrist-shoulder vertical alignment
- **Correct Form**: Vertical distance between wrist and shoulder (100-160 pixels)
- **Logic**: Calculates Y-axis difference between shoulder and wrist positions
- **Feedback**: "Good" (optimal range), "Too Low" (insufficient elevation)
- **Rep Counting**: Transitions from lowered (<100px) to raised (>140px)
- **Multi-Person**: Separate rep counting for each individual

### 3. Squat
**Primary Rule**: Knee angle and depth analysis  
- **Correct Form**: Knee angle between 90°-150° (proper squat depth)
- **Logic**: Measures angle between hip-knee-ankle triangle
- **Feedback**: "Correct" (good depth), "Too High" (insufficient depth), "Good" (acceptable)
- **Rep Counting**: Transitions from standing (>150°) to squatting (<100°)
- **Multi-Person**: Individual form analysis for each person

### 4. Jumping Jack
**Primary Rule**: Limb separation distance
- **Correct Form**: Hand distance >200px AND foot distance >100px
- **Logic**: Calculates horizontal distances between corresponding limbs
- **Feedback**: "Good" (arms and legs properly extended), "Closed" (insufficient separation)
- **Rep Counting**: Transitions from closed to open position
- **Multi-Person**: Synchronized analysis for group exercises

## Logic Behind the Rules

### Geometric Analysis Approach
1. **Angle Calculation**: Uses arctangent mathematics to compute joint angles
   ```python
   radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
   angle = np.abs(radians*180.0/np.pi)
   ```

2. **Distance Measurement**: Euclidean distance for limb separation
3. **Smoothing Algorithm**: Moving average filter to reduce noise
4. **State Machine**: Tracks exercise phases for accurate rep counting
5. **Person Tracking**: Individual state machines for multi-person scenarios

### Threshold Determination
- **Empirical Testing**: Thresholds derived from analyzing multiple sample videos
- **Biomechanical Principles**: Based on optimal exercise form guidelines
- **Adaptive Logic**: Different thresholds for different exercise phases
- **Person-Specific**: Individual calibration for multi-person analysis

## Tools & Technologies

### Core Technologies
- **Python 3.8+**: Primary programming language
- **MediaPipe**: Google's pose estimation framework (single-person)
- **OpenPose**: CMU's pose estimation framework (multi-person)
- **OpenCV**: Computer vision processing
- **NumPy**: Numerical computations
- **Pandas**: Data analysis and logging
- **Matplotlib**: Performance visualization

### Pose Estimation Frameworks

#### MediaPipe Integration
- **Use Case**: Single-person real-time analysis
- **Advantages**: Fast processing, lightweight, excellent for mobile
- **Keypoints**: 33 body landmarks
- **Performance**: 30+ FPS on standard hardware

#### OpenPose Integration
- **Use Case**: Multi-person detection and tracking
- **Advantages**: Superior multi-person handling, research-grade accuracy
- **Keypoints**: 18 body landmarks (COCO format)
- **Performance**: 15-25 FPS depending on number of people
- **Model Files Required**:
  - `pose_deploy_linevec.prototxt`
  - `pose_iter_440000.caffemodel`

### Web Framework
- **Flask**: Backend API server
- **HTML5/CSS3/JavaScript**: Frontend interface
- **Bootstrap**: Responsive design framework

### Data Processing
- **CSV Logging**: Frame-by-frame analysis storage
- **JSON Summaries**: Performance metrics compilation
- **Real-time Processing**: Live video analysis pipeline
- **Multi-Person Tracking**: Individual performance isolation

## Methodology

### 1. Pose Detection Pipeline
```
Video Input → Framework Selection → Keypoint Extraction → Coordinate Normalization
     ↓              ↓                        ↓                    ↓
Single Person → MediaPipe        Multi-Person → OpenPose
```

### 2. Multi-Person Analysis Engine
```
Multiple Keypoints → Person Identification → Individual Tracking → Comparative Analysis
```

### 3. Form Analysis Engine
```
Keypoints → Geometric Calculations → Rule Application → Feedback Generation → Person-Specific Metrics
```

### 4. Data Processing Flow
```
Real-time Analysis → Smoothing → Rep Counting → Performance Metrics → Visualization → Comparison
```

### 5. Output Generation
```
Processed Video + Multi-Person Overlays + Individual CSV Logs + Comparative Graphs + Summary Statistics
```

## Component Breakdown

### Core Components

#### 1. ExerciseAnalyzer Class (Single-Person)
- **Purpose**: MediaPipe-based single-person analysis
- **Functions**: Video processing, pose detection, rule application
- **Output**: Annotated videos, performance logs, statistical summaries

#### 2. MultiPersonExerciseAnalyzer Class (Multi-Person)
- **Purpose**: OpenPose-based multi-person analysis
- **Functions**: Multiple person detection, individual tracking, comparative analysis
- **Features**:
  - Person identification and color coding
  - Individual rep counting
  - Comparative performance metrics
  - Group exercise analysis

#### 3. OpenPoseDetector Class
- **Purpose**: Handle OpenPose model loading and inference
- **Functions**: Multi-person keypoint detection, confidence scoring
- **Fallback**: Simulation mode when model files unavailable

#### 4. Geometric Functions
- `calculate_angle()`: Joint angle computation
- `smooth_signal()`: Noise reduction
- `check_[exercise]()`: Exercise-specific form validation (works for both single and multi-person)

#### 5. Enhanced Web Interface
- **Upload System**: Drag-and-drop video upload
- **Analysis Mode Selection**: Single-person vs Multi-person
- **Exercise Selection**: Radio button interface for exercise types
- **Results Display**: Interactive performance dashboard with comparative analysis
- **Download System**: Access to all generated files


## Input & Output Specifications

### Input Requirements
- **Video Formats**: MP4, AVI, MOV, MKV, WMV
- **File Size**: Maximum 100MB
- **Duration**: 3-5 seconds 
- **Quality**: Minimum 480p resolution
- **Subject**: Single person (MediaPipe) or multiple people (OpenPose)
- **Lighting**: Well-lit environment preferred for optimal detection

### Output Deliverables

#### Single-Person Analysis
1. **Processed Video**: Original with pose overlays and real-time feedback
2. **Analysis Log**: Frame-by-frame CSV with timestamps and metrics
3. **Performance Summary**: JSON with aggregate statistics

#### Multi-Person Analysis
1. **Multi-Person Video**: Color-coded individual tracking and feedback
2. **Individual Logs**: Separate CSV files for each detected person
3. **Comparative Summary**: JSON with individual and group statistics
4. **Advanced Visualizations**: 
   - Individual metric progression over time
   - Comparative rep counting timeline  
   - Multi-person form accuracy distribution
   - Group tempo analysis charts
   - Performance ranking and comparison

## Challenges & Solutions

### 1. Multi-Person Detection Accuracy
**Challenge**: Distinguishing between multiple people and tracking consistency  
**Solutions Implemented**:
- **OpenPose Integration**: Superior multi-person detection capabilities
- **Person ID Tracking**: Consistent individual identification across frames
- **Confidence Thresholds**: Minimum detection confidence of 0.3 for multi-person
- **Color-Coded Visualization**: Clear visual distinction between individuals

### 2. Model File Management
**Challenge**: OpenPose requires large model files  
**Solutions**:
- **Automatic Download**: Instructions for model file acquisition
- **Fallback Simulation**: Testing mode when models unavailable
- **Model Validation**: Automatic checking of model file integrity
- **Setup Instructions**: Clear documentation for model installation

### 3. Performance Optimization
**Challenge**: Multi-person analysis requires more computational resources  
**Solutions**:
- **Adaptive Processing**: Automatic optimization based on person count
- **Frame Skipping**: Intelligent frame selection for performance
- **GPU Acceleration**: Optional GPU support for faster processing
- **Batch Processing**: Efficient handling of multiple videos

### 4. Individual Tracking Consistency
**Challenge**: Maintaining individual identity across frames  
**Solutions**:
- **Spatial Tracking**: Position-based person identification
- **Confidence Scoring**: Reliability-based tracking decisions
- **State Persistence**: Maintaining individual exercise states
- **Error Recovery**: Handling temporary detection failures

## Performance Metrics

### Analysis Accuracy
- **Single-Person (MediaPipe)**: 85-90% accuracy across test videos
- **Multi-Person (OpenPose)**: 80-85% accuracy per individual
- **Rep Counting**: 90-95% accuracy for clear exercise execution
- **Person Identification**: 85-90% consistency in multi-person scenarios

### System Performance
- **Single-Person Processing**: 2-3x real-time for analysis
- **Multi-Person Processing**: 1.5-2x real-time for 2-3 people
- **Memory Usage**: <1GB for multi-person analysis
- **File Output**: Comprehensive logs and visualizations under 100MB total

### Framework Comparison
| Feature | MediaPipe | OpenPose |
|---------|-----------|----------|
| **People Detected** | 1 | 2-10+ |
| **Processing Speed** | 30+ FPS | 15-25 FPS |
| **Accuracy** | 90% | 85% |
| **Model Size** | ~30MB | ~200MB |
| **Setup Complexity** | Easy | Moderate |


## Output (Frontend)

![image](https://github.com/user-attachments/assets/dae23e26-9c9e-4a74-ac8e-d4d701eb45ed)

### 1) Bicep Curl

https://drive.google.com/file/d/1n-uPZQ_zg9Z0eaFrgACela29OieV0L-U/view?usp=sharing

https://drive.google.com/file/d/1Lzhd3NUf0kfzrR5pwx7vgvnnnjzlBYSE/view?usp=sharing

![image](https://github.com/user-attachments/assets/1b3396f0-60b0-4e6c-a7b2-2438752d4135)

![image](https://github.com/user-attachments/assets/2b6c4f2a-a861-481b-8ad9-d5676e24f352)

![image](https://github.com/user-attachments/assets/40d3b957-0456-4f52-8328-7fc6c8100b28)

![image](https://github.com/user-attachments/assets/aa9c025d-36df-4d52-b259-ac3bdc1d0cc4)

![image](https://github.com/user-attachments/assets/8ad4578f-7da5-40a3-9d34-ca04e1e8694b)


### 2) Lateral Raise

https://drive.google.com/file/d/1jEcMRWTYSGWAIjMKxgrgBl85xi7hwYlx/view?usp=drive_link

https://drive.google.com/file/d/12If4iicuaF7TaJb5TwdnrpdOWtpwrpCd/view?usp=drive_link

![image](https://github.com/user-attachments/assets/8f91c1ae-f698-45a1-b8ad-57f75b355015)

![image](https://github.com/user-attachments/assets/91b54b6a-9fb7-4be8-8b72-9f6375c051c7)

![image](https://github.com/user-attachments/assets/3b582bc5-6ce4-423d-9393-2b96960b3233)

![image](https://github.com/user-attachments/assets/3eddb7d7-b5c3-48ec-b465-d484cdd6753e)

![image](https://github.com/user-attachments/assets/5f8c83bc-1952-4e34-98af-5077ec0c7754)


### 3) Jumping Jacks

https://drive.google.com/file/d/1COzB5uaYnbr5RDNWf77VVrizCge5gEco/view?usp=sharing

https://drive.google.com/file/d/1eZFgKIZ-W6qdt2jibts_8V-X4cFqI7-_/view?usp=sharing

![image](https://github.com/user-attachments/assets/9fbd81b6-f101-49ad-a12a-744f8e20de1d)

![image](https://github.com/user-attachments/assets/edbbe62e-5cba-4ccb-83a1-b21cfc3b8ff9)

![image](https://github.com/user-attachments/assets/c53c56d0-c6de-470c-9ce6-37d86b9a26d3)

![image](https://github.com/user-attachments/assets/542db5aa-3b43-4a2f-afb6-c60142aafeb1)

![image](https://github.com/user-attachments/assets/6a0b589a-ca3d-4b8b-9212-8ea7d546253a)


## 4) Squat

https://drive.google.com/file/d/1LMYAMR1h6kd0PoexnI8_58Q2F2OQ1w4V/view?usp=sharing

https://drive.google.com/file/d/16xNGptt8qNQtq4XUYyD7BMtdOKM7YxKw/view?usp=sharing

![image](https://github.com/user-attachments/assets/96c35344-ddd6-449d-ae20-bb9f2f8b98a0)

![image](https://github.com/user-attachments/assets/268ca62e-f6e4-4661-81ab-33011e864119)

![image](https://github.com/user-attachments/assets/5a79047d-1eee-40b0-babb-63eeb4f08845)

![image](https://github.com/user-attachments/assets/00cf70b3-0ffa-4ac7-ad6b-f18327fdd2b3)

![image](https://github.com/user-attachments/assets/43d2bc6d-ff3c-4ca2-83fd-37d2ac1c3061)



## 5) Handling Multiple people

https://drive.google.com/file/d/1TPnvi2YXgvfQFOpsV9cR-UNy93_VRBMx/view?usp=sharing

![image](https://github.com/user-attachments/assets/47d59881-f91b-4127-98d6-9b57bd53e4bb)

![form_accuracy_pie](https://github.com/user-attachments/assets/c5f47627-482d-495b-ae6d-8103bc673628)

![distance_over_time](https://github.com/user-attachments/assets/f134f50e-fbef-4ef9-aaf8-4ee8eb29b1d7)

![image](https://github.com/user-attachments/assets/da40de3c-9b50-4100-bc75-717a66595665)

![image](https://github.com/user-attachments/assets/41cc3951-1e0e-4adb-8f60-84157c09cb13)






{
    "persons": {
        "P0": {
            "total_reps": 8,
            "avg_distance": 298.31,
            "rep_times": [
                0.0,
                0.44,
                2.28,
                4.08,
                5.84,
                7.6,
                9.36,
                11.2
            ],
            "rep_intervals": [
                0.44,
                1.84,
                1.8,
                1.76,
                1.76,
                1.76,
                1.84
            ],
            "avg_tempo": 1.6
        },
        "P1": {
            "total_reps": 8,
            "avg_distance": 300.31,
            "rep_times": [
                0.0,
                0.48,
                2.32,
                4.04,
                5.84,
                7.64,
                9.44,
                11.2
            ],
            "rep_intervals": [
                0.48,
                1.84,
                1.72,
                1.8,
                1.8,
                1.8,
                1.76
            ],
            "avg_tempo": 1.6
        },
        
    "total_frames": 315
}






